{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/airctic/icevision/blob/master/notebooks/getting_started_semantic_segmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started with Semantic Segmentation using IceVision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Torch - Torchvision - IceVision - IceData - MMDetection - YOLOv5 - EfficientDet Installation\n",
    "!wget https://raw.githubusercontent.com/airctic/icevision/master/icevision_install.sh\n",
    "\n",
    "# Choose your installation target: cuda11 or cuda10 or cpu\n",
    "!bash icevision_install.sh cuda11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from icevision.all import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting and parsing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_url = 'https://s3.amazonaws.com/fast-ai-sample/camvid_tiny.tgz'\n",
    "data_dir = icedata.load_data(data_url, 'camvid_tiny') / 'camvid_tiny'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codes = np.loadtxt(data_dir/'codes.txt', dtype=str)\n",
    "class_map = ClassMap(list(codes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_dir = data_dir/'images'\n",
    "labels_dir = data_dir/'labels'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_files = get_image_files(images_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records = RecordCollection(SemanticSegmentationRecord)\n",
    "\n",
    "for image_file in pbar(image_files):\n",
    "    record = records.get_by_record_id(image_file.stem)\n",
    "\n",
    "    if record.is_new:\n",
    "        record.set_filepath(image_file)\n",
    "        record.set_img_size(get_img_size(image_file))\n",
    "        record.segmentation.set_class_map(class_map)\n",
    "\n",
    "    mask_file = SemanticMaskFile(labels_dir / f'{image_file.stem}_P.png')\n",
    "    record.segmentation.set_mask(mask_file)\n",
    "    \n",
    "records = records.autofix()\n",
    "train_records, valid_records = records.make_splits(RandomSplitter([0.8, 0.2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sample_records = random.choices(records, k=3)\n",
    "show_records(sample_records, ncols=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transforms and datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "presize, size = 512, 384\n",
    "presize, size = ImgSize(presize, int(presize*.75)), ImgSize(size, int(size*.75))\n",
    "\n",
    "aug_tfms = tfms.A.aug_tfms(presize=presize, size=size, pad=None,\n",
    "                           crop_fn=partial(tfms.A.RandomCrop, p=0.5),\n",
    "                           shift_scale_rotate=tfms.A.ShiftScaleRotate(rotate_limit=2),\n",
    "                          )\n",
    "train_tfms = tfms.A.Adapter([*aug_tfms, tfms.A.Normalize()])\n",
    "valid_tfms = tfms.A.Adapter([tfms.A.resize(size), tfms.A.Normalize()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = Dataset(train_records, train_tfms)\n",
    "valid_ds = Dataset(valid_records, valid_tfms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_samples = [train_ds[0] for _ in range(3)]\n",
    "show_samples(ds_samples, ncols=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7701202",
   "metadata": {},
   "source": [
    "# Select a library, model, and backbone\n",
    "\n",
    "In order to create a model, we need to:\n",
    "\n",
    "- Choose one of the **libraries** supported by IceVision\n",
    "- Choose one of the **models** supported by the library\n",
    "- Choose one of the **backbones** corresponding to a chosen model\n",
    "\n",
    "You can access any supported models by following the IceVision unified API, use code completion to explore the available models for each library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a model\n",
    "\n",
    "Selections only take two simple lines of code. For example, to try the `mmsegmentation` library using the `deeplabv3` model and the `resnet50_d8` backbone could be specified by:\n",
    "\n",
    "```python\n",
    "model_type = models.mmseg.deeplab3\n",
    "backbone = model_type.backbones.backbones.resnet50_d8\n",
    "```\n",
    "\n",
    "As pretrained models are used by default, we typically leave this out of the backbone creation step.\n",
    "\n",
    "We've selected a few of the many options below. You can easily pick which option you want to try by setting the value of `selection`. This shows you how easy it is to try new libraries, models, and backbones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0209ad39",
   "metadata": {},
   "outputs": [],
   "source": [
    "selection = 1\n",
    "\n",
    "\n",
    "if selection == 0:\n",
    "  model_type = models.fastai.unet\n",
    "  backbone = model_type.backbones.resnet34()\n",
    "\n",
    "if selection == 1:\n",
    "  model_type = models.mmseg.deeplabv3\n",
    "  backbone = model_type.backbones.resnet50_d8(pretrained=True)\n",
    "\n",
    "if selection == 2:\n",
    "  model_type = models.mmseg.deeplabv3\n",
    "  backbone = model_type.backbones.resnet50_d8(pretrained=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84dd5160",
   "metadata": {},
   "source": [
    "## Data Loader\n",
    "The Data Loader is specific to a model_type. The job of the data loader is to get items from a dataset and batch them up in the specific format required by each model. This is why creating the data loaders is separated from creating the datasets.\n",
    "\n",
    "We can take a look at the first batch of items from the `valid_dl`. Remember that the `valid_tfms` only resized (with padding) and normalized records, so different images, for example, are not returned each time. This is important to provide consistent validation during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = model_type.train_dl(train_ds, batch_size=8, num_workers=4, shuffle=True)\n",
    "valid_dl = model_type.valid_dl(valid_ds, batch_size=8, num_workers=4, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone = model_type.backbones.resnet34()\n",
    "model = model_type.model(backbone=backbone, num_classes=class_map.num_classes, img_size=size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining and training the `fastai` learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_camvid(pred, target):\n",
    "    # ignores void pixels\n",
    "    keep_idxs = target != class_map.get_by_name('Void')\n",
    "    target = target[keep_idxs]\n",
    "    pred = pred.argmax(dim=1)[keep_idxs]\n",
    "\n",
    "    return (pred==target).float().mean() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = model_type.fastai.learner(dls=[train_dl, valid_dl], model=model, metrics=[accuracy_camvid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fine_tune(10, 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type.show_results(model, valid_ds, num_samples=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model_type.predict(model, valid_ds)\n",
    "show_preds(preds=preds[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infer_dl = model_type.infer_dl([valid_ds[0]], batch_size=4, shuffle=False)\n",
    "preds = model_type.predict_from_dl(model, infer_dl, keep_images=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_sample(preds[0].pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a59a430",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fe738d56747ed9c8891b1c97864a5c22a0f14bdf3b7e6db02ccceae30cfa1132"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
